{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTSC670: Foundations of Machine Learning Models\n",
    "\n",
    "## Assignment 2: California Housing Prices Data Manipulation\n",
    "\n",
    "### Name:\n",
    "\n",
    "\n",
    "## CodeGrade\n",
    "Note that this assignment will be automatically graded through CodeGrade and you will have unlimited submission attempts.  When submitting to CodeGrade, your notebook should be named `assignment2.ipynb` and there should be no errors in the file or CodeGrade will not be able to grade it.  Before submitting, I suggest that you restart your kernel and attempt to run all cells again to ensure that there will be no errors when CodeGrade runs your script.  \n",
    "\n",
    "## Details\n",
    "\n",
    "The purpose of this assignment is to hone your data wrangling skills.  It has been estimated that up to 80% of a Data Scientist's role is data cleaning and manipulation tasks to get the data ready for modeling/machine learning.  Your task for this assignment is to perform the data preparation steps as instructed below. \n",
    "\n",
    "In the \"End-to-End Machine Learning\" module, you will be working with the California Housing Prices dataset that is based on data from the 1990 California census.  This dataset is often used to practice building a model to predict housing prices.  I have downloaded the original data and made various changes to it.  Your job will be to clean and manipulate the data to get it back to the proper format.  \n",
    "\n",
    "*Note that your final dataset will <b>not</b> match the dataset that we will use in the class module.  This is on purpose so that students cannot download the data from various online sources and pass it off as their \"cleaned\" data.* \n",
    "\n",
    "### Files and Data Dictionary\n",
    "\n",
    "The files that you will be working with, and that can be found on Brightspace, are:\n",
    "\n",
    "- <u>long_lat.csv</u>: longitude and latitude coordinates for all instances\n",
    "- <u>cal_housing_low.csv</u>: instances with median house values in the lower 25% percentile\n",
    "- <u>cal_housing_medium.csv</u>: instances with median house values between the lower and upper percentiles\n",
    "- <u>cal_housing_high.csv</u>: instances with median house values in the upper 75% percentile\n",
    "- <u>ocean_proximity.csv</u>: longitude and latitude coordinates along with their corresponding category \n",
    "\n",
    "The data dictionary for the columns in the files are:\n",
    "\n",
    "- <u>id</u>: unique ID number for the respective district (also called block groups)\n",
    "- <u>longitude</u>: longitude coordinates for the respective district\n",
    "- <u>latitude</u>: latitude coordinates for the respective district\n",
    "- <u>state</u>: US state for the respective district \n",
    "- <u>medianHouseValue</u>: median house value in the respective district (this will be the target or response variable)\n",
    "- <u>housingMedianAge</u>: median house age in the respective district\n",
    "- <u>totalBedrooms</u>: total bedrooms for all houses in the respective district\n",
    "- <u>totalRooms</u>: total number of rooms for all houses in the respective district\n",
    "- <u>households</u>: total households for all houses in the respective district\n",
    "- <u>population</u>: total population for all houses in the respective district\n",
    "- <u>medianIncome</u>: median income for households in the respective district\n",
    "- <u>ocean_proximity</u>: categorical variable for each respective longitude and latitude pair  \n",
    "\n",
    "### Data Cleaning\n",
    "In order to clean the data, you will need to perform the following steps, although not necessarily in this order:\n",
    "- Make sure that your notebook is organized and that you include specific comments that explain your code.  Assignments will be manually checked at the end of the course and points may be deducted for insufficient comments. (see Assignment Rubric)\n",
    "- Use only base Python, Pandas, or NumPy for this assignment.  \n",
    "- Combine the files together, as appropriate, so that you have one final DataFrame\n",
    "- The final DataFrame must be named `housing`\n",
    "- Sort the final `housing` DataFrame by `id` in ascending order\n",
    "- Drop any rows with a missing value for the `medianHouseValue` column\n",
    "- Fill any rows with a missing value for the `housingMedianAge` column with the median value for that column\n",
    "- Drop the `state` column since it doesn't offer any added value\n",
    "- In order to match the data that will be worked on in class, you will make the following changes to the values:\n",
    "  - Scale the `medianIncome` to express the values in $10,000 of dollars (example: `150000` will become `15`, `30000` will become `3`, `15000` will become `1.5`, etc)\n",
    "  - In your textbook, it discusses that the median income values have been capped on both the lower and upper ends.  In order to recreate this data, change any values in the `medianIncome` column that are `0.4999` or lower to `0.4999` and change any values that are `15.0001` and higher to `15.0001`.  This step should be done after the previous step.  Take a look at [this stackoverflow answer](https://stackoverflow.com/questions/38876816/change-value-of-a-dataframe-column-based-on-a-filter) if you need help with this step.\n",
    "  - Revert the `medianHouseValue` back to actual dollars (example: `150` will become `150000`, `300` will become `300000`, etc)\n",
    "- Update the column names and column order as shown below to match the data from the module:\n",
    "  - longitude\n",
    "  - latitude\n",
    "  - housing_median_age\n",
    "  - total_rooms\n",
    "  - total_bedrooms\n",
    "  - population\n",
    "  - households\n",
    "  - median_income\n",
    "  - median_house_value\n",
    "  - ocean_proximity\n",
    "- Change all columns to a float data type except for the `ocean_proximity` column.  The `ocean_proximity` column should remain a string/object data type (do not update this to a categorical data type since that will be done later when working with the module data).\n",
    "- Reset the DataFrame index so that it goes from `0` to `n-1`, where `n` is the number of rows in your DataFrame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Do not change this option; This allows the CodeGrade auto grading to function correctly\n",
    "pd.set_option('display.max_columns', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "# Insert as many cells as you need, but be sure your code is very neat and very well documented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
